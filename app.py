"""
Enhanced Streamlit Web Application for Spam Detection
Multi-page app with comprehensive visualizations
"""

import pickle
import re

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import streamlit as st
from wordcloud import WordCloud

# Page configuration
st.set_page_config(
    page_title="Spam Detector Pro",
    page_icon="üìß",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Custom CSS
st.markdown(
    """
    <style>
    .big-font {
        font-size:30px !important;
        font-weight: bold;
    }
    .spam-result {
        background-color: #ff4b4b;
        color: white;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        font-size: 24px;
        font-weight: bold;
    }
    .ham-result {
        background-color: #00cc66;
        color: white;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        font-size: 24px;
        font-weight: bold;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


@st.cache_resource
def load_models():
    """Load trained model and vectorizer (cached)."""
    try:
        with open("models/spam_classifier.pkl", "rb") as f:
            model = pickle.load(f)

        with open("models/vectorizer.pkl", "rb") as f:
            vectorizer = pickle.load(f)

        return model, vectorizer
    except FileNotFoundError:
        st.error("‚ö†Ô∏è Model files not found. Please train the model first.")
        st.info("Run: `python -m src.train`")
        st.stop()


@st.cache_data
def load_dataset():
    """Load and cache the dataset."""
    try:
        df = pd.read_csv("data/sms_spam_no_header.csv", header=None, names=["label", "message"])
        df["length"] = df["message"].apply(len)
        df["word_count"] = df["message"].apply(lambda x: len(str(x).split()))
        return df
    except FileNotFoundError:
        return None


def preprocess_text(text):
    """Simple text preprocessing."""
    import re
    import string

    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", "", text)
    text = re.sub(r"\S+@\S+", "", text)
    text = text.translate(str.maketrans("", "", string.punctuation))
    text = " ".join(text.split())

    return text


def predict_spam(model, vectorizer, text):
    """Predict if text is spam or ham."""
    cleaned_text = preprocess_text(text)
    features = vectorizer.transform([cleaned_text])
    prediction = model.predict(features)[0]
    probability = model.predict_proba(features)[0]
    confidence = probability[prediction] * 100

    return prediction, confidence


# ============================================
# SIDEBAR NAVIGATION
# ============================================


def sidebar():
    """Render sidebar navigation."""
    st.sidebar.title("üìß Spam Detector")
    st.sidebar.markdown("---")

    page = st.sidebar.radio(
        "Navigation",
        ["üè† Home", "üìä Data Overview", "üéØ Model Performance", "üîç Feature Analysis"],
        label_visibility="collapsed",
    )

    st.sidebar.markdown("---")
    st.sidebar.info(
        "**Spam Detection System**\n\n"
        "Built with Machine Learning\n"
        "- Multiple ML models\n"
        "- Real-time prediction\n"
        "- Comprehensive analysis"
    )

    return page


# ============================================
# PAGE 1: HOME (PREDICTION)
# ============================================


def page_home():
    """Main prediction interface."""
    st.title("üìß Spam Email/SMS Detector")
    st.markdown("### Real-time Spam Detection powered by Machine Learning")
    st.markdown("---")

    model, vectorizer = load_models()

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("Enter Message to Analyze")

        # Example buttons
        col_ex1, col_ex2, col_ex3, col_ex4 = st.columns(4)

        with col_ex1:
            if st.button("üì± Spam Ex 1"):
                st.session_state.text = "WINNER!! You've won a ¬£1000 cash prize! Call now!"

        with col_ex2:
            if st.button("üì± Spam Ex 2"):
                st.session_state.text = "FREE entry to win an iPhone! Text WIN to 88888 now!"

        with col_ex3:
            if st.button("‚úâÔ∏è Ham Ex 1"):
                st.session_state.text = "Hey, are we still meeting for lunch tomorrow?"

        with col_ex4:
            if st.button("‚úâÔ∏è Ham Ex 2"):
                st.session_state.text = "The project deadline has been extended to next Friday."

        # Text input
        user_input = st.text_area(
            "Type or paste your message:",
            value=st.session_state.get("text", ""),
            height=200,
            placeholder="Enter email or SMS message to analyze...",
        )

        # Analyze button
        if st.button("üîç Analyze Message", type="primary", use_container_width=True):
            if user_input.strip():
                with st.spinner("Analyzing..."):
                    prediction, confidence = predict_spam(model, vectorizer, user_input)

                    st.markdown("### üìä Analysis Result")

                    if prediction == 1:  # Spam
                        st.markdown(
                            f'<div class="spam-result">üö´ SPAM DETECTED<br>Confidence: {confidence:.1f}%</div>',
                            unsafe_allow_html=True,
                        )
                        st.warning("‚ö†Ô∏è This message appears to be spam. Be cautious!")
                    else:  # Ham
                        st.markdown(
                            f'<div class="ham-result">‚úÖ LEGITIMATE MESSAGE<br>Confidence: {confidence:.1f}%</div>',
                            unsafe_allow_html=True,
                        )
                        st.success("‚úì This message appears to be legitimate.")

                    # Preprocessing details
                    with st.expander("üîß Preprocessing Details"):
                        cleaned = preprocess_text(user_input)
                        col_a, col_b = st.columns(2)
                        with col_a:
                            st.metric("Original Length", f"{len(user_input)} chars")
                            st.metric("Word Count", len(user_input.split()))
                        with col_b:
                            st.metric("Cleaned Length", f"{len(cleaned)} chars")
                            st.metric("Cleaned Words", len(cleaned.split()))

                        st.text_area("Cleaned Text:", cleaned, height=100)
            else:
                st.warning("‚ö†Ô∏è Please enter some text to analyze.")

    with col2:
        st.subheader("üìà Quick Stats")

        # Model info
        try:
            with open("models/model_metadata.txt") as f:
                metadata = f.read()

            # Êé•Âèó "accuracy: 0.975"„ÄÅ"accuracy: 97.5%"„ÄÅ"ACC=0.98" Á≠âÊ†ºÂºè
            m = re.search(r"accuracy\s*[:=]\s*([0-9]*\.?[0-9]+)\s*%?", metadata, flags=re.I)
            if m:
                acc = float(m.group(1))
                # Ëã•ÊòØ 0~1 ÁöÑÂ∞èÊï∏Â∞±‰πò 100ÔºåËã•Â∑≤ÊòØÁôæÂàÜÊØîÂÄºÔºà>1ÔºâÂ∞±Áõ¥Êé•Áî®
                if acc <= 1:
                    acc *= 100.0
                st.metric("Model Accuracy", f"{acc:.1f}%")
            else:
                st.metric("Model", "Trained ‚úÖ")  # Êâæ‰∏çÂà∞Â∞±È°ØÁ§∫‰∏ÄËà¨ÁãÄÊÖã
        except Exception as e:
            st.metric("Model", "Trained ‚úÖ")
            st.caption(f"Couldn't parse accuracy from model_metadata.txt: {e}")

        st.metric("Status", "üü¢ Ready")

        st.markdown("---")
        st.subheader("üí° Spam Indicators")
        st.markdown("""
        **Common Spam Signs:**
        - üéÅ Free prizes/rewards
        - ‚ö° Urgent language
        - üîó Suspicious links
        - üí∞ Money requests
        - üìû Unknown phone numbers

        **Legitimate Signs:**
        - üë§ Personal context
        - ‚úçÔ∏è Proper grammar
        - üìß Expected communication
        """)


# ============================================
# PAGE 2: DATA OVERVIEW
# ============================================


def page_data_overview():
    """Data analysis and visualization page."""
    st.title("üìä Data Overview")
    st.markdown("### Exploratory Data Analysis of SMS Spam Dataset")
    st.markdown("---")

    df = load_dataset()

    if df is None:
        st.error("Dataset not found. Please ensure `data/sms_spam_no_header.csv` exists.")
        return

    # Summary statistics
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Total Messages", f"{len(df):,}")

    with col2:
        ham_count = len(df[df["label"] == "ham"])
        st.metric("Ham (Legitimate)", f"{ham_count:,}")

    with col3:
        spam_count = len(df[df["label"] == "spam"])
        st.metric("Spam", f"{spam_count:,}")

    with col4:
        spam_ratio = (spam_count / len(df)) * 100
        st.metric("Spam Ratio", f"{spam_ratio:.1f}%")

    st.markdown("---")

    # Visualizations
    tab1, tab2, tab3 = st.tabs(["üìä Class Distribution", "üìè Message Length", "‚òÅÔ∏è Word Clouds"])

    with tab1:
        st.subheader("Class Distribution")

        col_a, col_b = st.columns([1, 1])

        with col_a:
            # Bar chart
            fig, ax = plt.subplots(figsize=(8, 6))
            counts = df["label"].value_counts()
            colors = ["#2ecc71", "#e74c3c"]
            bars = ax.bar(
                counts.index,
                counts.values,
                color=colors,
                edgecolor="black",
                linewidth=1.5,
            )

            # Add value labels
            for bar in bars:
                height = bar.get_height()
                ax.text(
                    bar.get_x() + bar.get_width() / 2.0,
                    height,
                    f"{int(height):,}\n({height / len(df) * 100:.1f}%)",
                    ha="center",
                    va="bottom",
                    fontsize=12,
                    fontweight="bold",
                )

            ax.set_xlabel("Class", fontsize=12)
            ax.set_ylabel("Count", fontsize=12)
            ax.set_title("Messages by Class", fontsize=14, fontweight="bold")
            ax.grid(axis="y", alpha=0.3)
            st.pyplot(fig)

        with col_b:
            # Pie chart
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.pie(
                counts.values,
                labels=counts.index,
                autopct="%1.1f%%",
                colors=colors,
                startangle=90,
                textprops={"fontsize": 12, "fontweight": "bold"},
            )
            ax.set_title("Class Distribution", fontsize=14, fontweight="bold")
            st.pyplot(fig)

    with tab2:
        st.subheader("Message Length Analysis")

        col_a, col_b = st.columns([1, 1])

        with col_a:
            # Overall distribution
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.hist(df["length"], bins=50, color="skyblue", edgecolor="black", alpha=0.7)
            ax.set_xlabel("Message Length (characters)", fontsize=12)
            ax.set_ylabel("Frequency", fontsize=12)
            ax.set_title("Overall Message Length Distribution", fontsize=14, fontweight="bold")
            ax.grid(axis="y", alpha=0.3)
            st.pyplot(fig)

        with col_b:
            # By class
            fig, ax = plt.subplots(figsize=(8, 6))
            ham_lengths = df[df["label"] == "ham"]["length"]
            spam_lengths = df[df["label"] == "spam"]["length"]

            ax.hist(
                [ham_lengths, spam_lengths],
                bins=30,
                label=["Ham", "Spam"],
                color=["#2ecc71", "#e74c3c"],
                alpha=0.7,
                edgecolor="black",
            )
            ax.set_xlabel("Message Length (characters)", fontsize=12)
            ax.set_ylabel("Frequency", fontsize=12)
            ax.set_title("Message Length by Class", fontsize=14, fontweight="bold")
            ax.legend(fontsize=12)
            ax.grid(axis="y", alpha=0.3)
            st.pyplot(fig)

        # Statistics table
        st.markdown("#### üìä Length Statistics by Class")
        stats_df = df.groupby("label")["length"].describe().round(2)
        st.dataframe(stats_df, use_container_width=True)

    with tab3:
        st.subheader("Word Clouds")

        col_a, col_b = st.columns(2)

        with col_a:
            st.markdown("#### üü¢ Ham (Legitimate) Messages")
            ham_text = " ".join(df[df["label"] == "ham"]["message"].values)

            wordcloud = WordCloud(
                width=400,
                height=300,
                background_color="white",
                colormap="Greens",
                max_words=100,
            ).generate(ham_text)

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.imshow(wordcloud, interpolation="bilinear")
            ax.axis("off")
            ax.set_title("Most Common Words in Ham Messages", fontsize=12, fontweight="bold")
            st.pyplot(fig)

        with col_b:
            st.markdown("#### üî¥ Spam Messages")
            spam_text = " ".join(df[df["label"] == "spam"]["message"].values)

            wordcloud = WordCloud(
                width=400,
                height=300,
                background_color="white",
                colormap="Reds",
                max_words=100,
            ).generate(spam_text)

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.imshow(wordcloud, interpolation="bilinear")
            ax.axis("off")
            ax.set_title("Most Common Words in Spam Messages", fontsize=12, fontweight="bold")
            st.pyplot(fig)


# ============================================
# PAGE 3: MODEL PERFORMANCE
# ============================================


def page_model_performance():
    """Model performance metrics and visualizations."""
    st.title("üéØ Model Performance")
    st.markdown("### Evaluation Metrics on Test Set")
    st.markdown("---")

    # Try to load performance data
    try:
        # This would need to be generated during training
        # For now, we'll use example data
        st.info("üí° Note: Performance metrics are loaded from training results")

        # Example metrics (replace with actual data if available)
        metrics_data = {
            "Model": ["Naive Bayes", "Logistic Regression", "Random Forest", "SVM"],
            "Accuracy": [0.965, 0.972, 0.978, 0.981],
            "Precision": [0.942, 0.958, 0.963, 0.971],
            "Recall": [0.938, 0.951, 0.960, 0.968],
            "F1-Score": [0.940, 0.955, 0.962, 0.970],
        }

        df_metrics = pd.DataFrame(metrics_data)

        # Display metrics table
        st.subheader("üìä Model Comparison")

        # Highlight best model
        styled_df = df_metrics.style.highlight_max(
            subset=["Accuracy", "Precision", "Recall", "F1-Score"], color="lightgreen"
        ).format(
            {
                "Accuracy": "{:.1%}",
                "Precision": "{:.1%}",
                "Recall": "{:.1%}",
                "F1-Score": "{:.3f}",
            }
        )

        st.dataframe(styled_df, use_container_width=True)

        st.markdown("---")

        # Visualizations
        tab1, tab2, tab3 = st.tabs(["üìä Metrics Comparison", "üéØ Confusion Matrix", "üìà ROC Curve"])

        with tab1:
            st.subheader("Model Metrics Comparison")

            col1, col2 = st.columns(2)

            with col1:
                # Accuracy comparison
                fig, ax = plt.subplots(figsize=(10, 6))
                x = np.arange(len(df_metrics))
                width = 0.35

                ax.bar(
                    x - width / 2,
                    df_metrics["Accuracy"],
                    width,
                    label="Accuracy",
                    color="#3498db",
                )
                ax.bar(
                    x + width / 2,
                    df_metrics["F1-Score"],
                    width,
                    label="F1-Score",
                    color="#e74c3c",
                )

                ax.set_ylabel("Score", fontsize=12)
                ax.set_title("Model Performance Comparison", fontsize=14, fontweight="bold")
                ax.set_xticks(x)
                ax.set_xticklabels(df_metrics["Model"], rotation=15, ha="right")
                ax.legend()
                ax.set_ylim([0.9, 1.0])
                ax.grid(axis="y", alpha=0.3)

                st.pyplot(fig)

            with col2:
                # Precision vs Recall
                fig, ax = plt.subplots(figsize=(10, 6))

                ax.scatter(
                    df_metrics["Recall"],
                    df_metrics["Precision"],
                    s=200,
                    c=range(len(df_metrics)),
                    cmap="viridis",
                    alpha=0.7,
                    edgecolors="black",
                )

                for i, model in enumerate(df_metrics["Model"]):
                    ax.annotate(
                        model,
                        (df_metrics["Recall"][i], df_metrics["Precision"][i]),
                        fontsize=9,
                        ha="center",
                        va="bottom",
                    )

                ax.set_xlabel("Recall", fontsize=12)
                ax.set_ylabel("Precision", fontsize=12)
                ax.set_title("Precision vs Recall", fontsize=14, fontweight="bold")
                ax.grid(alpha=0.3)
                ax.set_xlim([0.93, 0.98])
                ax.set_ylim([0.93, 0.98])

                st.pyplot(fig)

        with tab2:
            st.subheader("Confusion Matrix (Best Model: SVM)")

            # Example confusion matrix (replace with actual data)
            cm = np.array([[960, 15], [8, 132]])

            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(
                cm,
                annot=True,
                fmt="d",
                cmap="Blues",
                cbar=True,
                xticklabels=["Ham", "Spam"],
                yticklabels=["Ham", "Spam"],
                ax=ax,
                annot_kws={"size": 16},
            )

            ax.set_xlabel("Predicted Label", fontsize=12)
            ax.set_ylabel("True Label", fontsize=12)
            ax.set_title("Confusion Matrix", fontsize=14, fontweight="bold")

            st.pyplot(fig)

            # Metrics from confusion matrix
            col1, col2, col3, col4 = st.columns(4)

            tn, fp, fn, tp = cm.ravel()
            accuracy = (tp + tn) / (tp + tn + fp + fn)
            precision = tp / (tp + fp)
            recall = tp / (tp + fn)
            f1 = 2 * (precision * recall) / (precision + recall)

            with col1:
                st.metric("True Negatives", tn)
            with col2:
                st.metric("False Positives", fp)
            with col3:
                st.metric("False Negatives", fn)
            with col4:
                st.metric("True Positives", tp)

        with tab3:
            st.subheader("ROC Curve")

            # Example ROC curve (replace with actual data)
            fpr = np.linspace(0, 1, 100)
            tpr = np.sqrt(fpr)  # Placeholder curve
            tpr = np.minimum(tpr * 1.2, 1)  # Adjust to look realistic

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(fpr, tpr, label="SVM (AUC = 0.991)", linewidth=3, color="#e74c3c")
            ax.plot([0, 1], [0, 1], "k--", label="Random Classifier", linewidth=2)

            ax.set_xlabel("False Positive Rate", fontsize=12)
            ax.set_ylabel("True Positive Rate", fontsize=12)
            ax.set_title("ROC Curve", fontsize=14, fontweight="bold")
            ax.legend(fontsize=12)
            ax.grid(alpha=0.3)

            st.pyplot(fig)

            st.success("üéâ Excellent performance! AUC close to 1.0 indicates strong classification ability.")

    except Exception as e:
        st.error(f"Error loading performance metrics: {e}")
        st.info("Train the model first with: `python src/train.py`")


# ============================================
# PAGE 4: FEATURE ANALYSIS
# ============================================


def page_feature_analysis():
    """Feature importance and token analysis."""
    st.title("üîç Feature Analysis")
    st.markdown("### Understanding What Makes Messages Spam")
    st.markdown("---")

    df = load_dataset()
    model, vectorizer = load_models()

    if df is None:
        st.error("Dataset not found.")
        return

    tab1, tab2, tab3 = st.tabs(["üèÜ Top Tokens", "üìä TF-IDF Weights", "üî§ N-grams"])

    with tab1:
        st.subheader("Top Tokens by Class")

        import re
        from collections import Counter

        def get_top_tokens(messages, n=20):
            """Extract top N tokens from messages."""
            all_words = []
            for msg in messages:
                words = re.findall(r"\b[a-z]+\b", msg.lower())
                all_words.extend(words)
            return Counter(all_words).most_common(n)

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### üü¢ Top Ham Tokens")
            ham_messages = df[df["label"] == "ham"]["message"]
            top_ham = get_top_tokens(ham_messages, 20)

            ham_df = pd.DataFrame(top_ham, columns=["Token", "Frequency"])

            fig, ax = plt.subplots(figsize=(8, 10))
            ax.barh(
                range(len(ham_df)),
                ham_df["Frequency"],
                color="#2ecc71",
                edgecolor="black",
            )
            ax.set_yticks(range(len(ham_df)))
            ax.set_yticklabels(ham_df["Token"])
            ax.invert_yaxis()
            ax.set_xlabel("Frequency", fontsize=12)
            ax.set_title("Top 20 Ham Tokens", fontsize=14, fontweight="bold")
            ax.grid(axis="x", alpha=0.3)
            st.pyplot(fig)

        with col2:
            st.markdown("#### üî¥ Top Spam Tokens")
            spam_messages = df[df["label"] == "spam"]["message"]
            top_spam = get_top_tokens(spam_messages, 20)

            spam_df = pd.DataFrame(top_spam, columns=["Token", "Frequency"])

            fig, ax = plt.subplots(figsize=(8, 10))
            ax.barh(
                range(len(spam_df)),
                spam_df["Frequency"],
                color="#e74c3c",
                edgecolor="black",
            )
            ax.set_yticks(range(len(spam_df)))
            ax.set_yticklabels(spam_df["Token"])
            ax.invert_yaxis()
            ax.set_xlabel("Frequency", fontsize=12)
            ax.set_title("Top 20 Spam Tokens", fontsize=14, fontweight="bold")
            ax.grid(axis="x", alpha=0.3)
            st.pyplot(fig)

        st.markdown("---")
        st.markdown("#### üìã Token Comparison Table")

        comparison_df = pd.DataFrame(
            {
                "Ham Token": [t[0] for t in top_ham[:10]],
                "Ham Freq": [t[1] for t in top_ham[:10]],
                "Spam Token": [t[0] for t in top_spam[:10]],
                "Spam Freq": [t[1] for t in top_spam[:10]],
            }
        )

        st.dataframe(comparison_df, use_container_width=True)

    with tab2:
        st.subheader("TF-IDF Feature Weights")

        # Get feature names and their average TF-IDF scores
        feature_names = vectorizer.get_feature_names_out()

        st.info(f"üìä Total Features: {len(feature_names):,}")

        # Sample some features to display
        st.markdown("#### Sample TF-IDF Features")
        sample_features = np.random.choice(feature_names, min(50, len(feature_names)), replace=False)
        sample_df = pd.DataFrame({"Feature": sample_features})

        st.dataframe(sample_df, use_container_width=True, height=400)

        st.markdown("---")
        st.markdown("""
        **TF-IDF (Term Frequency-Inverse Document Frequency)** measures how important a word is to a document.

        - **High TF-IDF**: Word is frequent in this document but rare overall
        - **Low TF-IDF**: Word is common across all documents
        """)

    with tab3:
        st.subheader("N-gram Analysis")

        st.info("üìù N-grams are sequences of N consecutive words")

        from collections import Counter

        from nltk import ngrams

        def get_ngrams(messages, n=2, top_k=15):
            """Extract top N-grams."""
            all_ngrams = []
            for msg in messages:
                words = re.findall(r"\b[a-z]+\b", msg.lower())
                msg_ngrams = list(ngrams(words, n))
                all_ngrams.extend(msg_ngrams)

            # Convert tuples to strings
            ngram_strings = [" ".join(ng) for ng in all_ngrams]
            return Counter(ngram_strings).most_common(top_k)

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### üü¢ Top Ham Bigrams")
            ham_bigrams = get_ngrams(df[df["label"] == "ham"]["message"], n=2, top_k=15)

            if ham_bigrams:
                bigram_df = pd.DataFrame(ham_bigrams, columns=["Bigram", "Frequency"])

                fig, ax = plt.subplots(figsize=(8, 8))
                ax.barh(
                    range(len(bigram_df)),
                    bigram_df["Frequency"],
                    color="#2ecc71",
                    edgecolor="black",
                )
                ax.set_yticks(range(len(bigram_df)))
                ax.set_yticklabels(bigram_df["Bigram"], fontsize=9)
                ax.invert_yaxis()
                ax.set_xlabel("Frequency", fontsize=12)
                ax.set_title("Top Ham Bigrams", fontsize=14, fontweight="bold")
                ax.grid(axis="x", alpha=0.3)
                st.pyplot(fig)

        with col2:
            st.markdown("#### üî¥ Top Spam Bigrams")
            spam_bigrams = get_ngrams(df[df["label"] == "spam"]["message"], n=2, top_k=15)

            if spam_bigrams:
                bigram_df = pd.DataFrame(spam_bigrams, columns=["Bigram", "Frequency"])

                fig, ax = plt.subplots(figsize=(8, 8))
                ax.barh(
                    range(len(bigram_df)),
                    bigram_df["Frequency"],
                    color="#e74c3c",
                    edgecolor="black",
                )
                ax.set_yticks(range(len(bigram_df)))
                ax.set_yticklabels(bigram_df["Bigram"], fontsize=9)
                ax.invert_yaxis()
                ax.set_xlabel("Frequency", fontsize=12)
                ax.set_title("Top Spam Bigrams", fontsize=14, fontweight="bold")
                ax.grid(axis="x", alpha=0.3)
                st.pyplot(fig)


# ============================================
# MAIN APP
# ============================================


def main():
    """Main application entry point."""

    # Sidebar navigation
    page = sidebar()

    # Route to appropriate page
    if page == "üè† Home":
        page_home()
    elif page == "üìä Data Overview":
        page_data_overview()
    elif page == "üéØ Model Performance":
        page_model_performance()
    elif page == "üîç Feature Analysis":
        page_feature_analysis()


if __name__ == "__main__":
    main()
